{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CareerJetMalta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG4huG5eG_OH"
      },
      "source": [
        "# Scraping CareerJet!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hPjASSXkLmh"
      },
      "source": [
        "https://www.careerjet.com.mt/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K7XiuWpCu2y"
      },
      "source": [
        "We first load the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsGNzKIgCpN5"
      },
      "source": [
        "!apt install chromium-chromedriver\r\n",
        "!pip install selenium\r\n",
        "from selenium import webdriver\r\n",
        "options = webdriver.ChromeOptions()\r\n",
        "options.add_argument('--headless')\r\n",
        "options.add_argument('--no-sandbox')\r\n",
        "options.add_argument('--disable-dev-shm-usage')\r\n",
        "\r\n",
        "from selenium.webdriver.common.keys import Keys\r\n",
        "import pandas as pd\r\n",
        "from time import sleep\r\n",
        "import requests\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import cv2\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "import os\r\n",
        "drive.mount(\"/content/drive\")\r\n",
        "pathOut = \"/content/drive/MyDrive/Colab Notebooks/Outputs\"\r\n",
        "os.chdir(pathOut)\r\n",
        "\r\n",
        "import sqlite3\r\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUnb4hADyOif"
      },
      "source": [
        "# Adding data to the current database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mdNssVbZDGfm"
      },
      "source": [
        "wd = webdriver.Chrome(options=options)\n",
        "\n",
        "def CreateAppendDB(jobdata):\n",
        "    db=sqlite3.connect(\"MaltaJobs.db\")\n",
        "    db.row_factory=sqlite3.Row\n",
        "    db.execute(\"\"\"create table if not exists \n",
        "    Jobs(url TEXT PRIMARY KEY        NOT NULL,\n",
        "         title              TEXT     NOT NULL,\n",
        "         company            TEXT     NOT NULL,\n",
        "         date_added         TEXT     NOT NULL\n",
        "         );\"\"\")\n",
        "    for x in range(0,len(jobdata)):\n",
        "      try:\n",
        "        db.execute(\"INSERT into Jobs(url,title,company,date_added) values(?,?,?,?)\",\n",
        "                   (jobdata[\"url\"][x],jobdata[\"title\"][x],jobdata[\"company\"][x],jobdata[\"date_added\"][x]))\n",
        "      except Exception as e:\n",
        "        print(str(e))\n",
        "    db.commit()\n",
        "\n",
        "#@title\n",
        "def scrolldown(N):\n",
        "    for z in range(1,N):\n",
        "        wd.find_element_by_css_selector(\"body\").send_keys(Keys.ARROW_DOWN)\n",
        "\n",
        "def ScrapePage(url):\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "def SearchScrape(role,location):\n",
        "    sleep(1)\n",
        "    wd.get(\"https://www.careerjet.com.mt/\")\n",
        "    wd.find_element_by_id(\"s\").send_keys(role)\n",
        "    wd.find_element_by_id(\"l\").send_keys(location)\n",
        "    sleep(1)\n",
        "    wd.find_element_by_xpath(\"/html/body/main/div/form/div/p/button\").click()\n",
        "    sleep(4)\n",
        "    try:\n",
        "      results = int(wd.find_element_by_xpath(\"/html/body/main/div/div/div/header/p[2]/span[1]\").text.split(\" \")[0])\n",
        "    except:\n",
        "      res = wd.find_element_by_xpath(\"/html/body/main/div/div/div/header/p[2]/span[1]\").text.split(\" \")[0]\n",
        "      res = res.replace(\",\",\"\")\n",
        "      results = int(res)\n",
        "    sleep(1)\n",
        "\n",
        "    while True:\n",
        "        sleep(2)\n",
        "        x=0\n",
        "        link = [j.get_attribute(\"href\") for j in wd.find_elements_by_css_selector(\"a\")]\n",
        "        joblink = []\n",
        "        for m in link:\n",
        "            if \"jobad\" in m:\n",
        "                joblink.append(m)\n",
        "        print(len(joblink))\n",
        "        if len(joblink) >= results:\n",
        "            break\n",
        "        while x<=500:\n",
        "            try:\n",
        "                wd.find_element_by_id(\"more-jobs\").click()\n",
        "                break\n",
        "            except:\n",
        "                scrolldown(1)\n",
        "                x=x+1\n",
        "    return(joblink)\n",
        "\n",
        "def ScrapeVec(urlvec):\n",
        "    title = []\n",
        "    company = []\n",
        "    for p in urlvec:\n",
        "        soup = ScrapePage(p)\n",
        "        try:\n",
        "            title.append(soup.find_all(\"h1\")[0].text)\n",
        "        except:\n",
        "            title.append(\"No title found\")\n",
        "        try:\n",
        "            company.append(soup.findAll(\"p\", {\"class\": \"company\"})[0].text.strip())\n",
        "        except:\n",
        "            company.append(\"No company found\")\n",
        "    ScrapedData = pd.DataFrame({\n",
        "        \"title\": title,\n",
        "        \"company\": company\n",
        "    })\n",
        "    return(ScrapedData)\n",
        "\n",
        "def Main():\n",
        "    role = \"\"\n",
        "    location = \"malta\"\n",
        "    urlvec = SearchScrape(role,location)\n",
        "    jobdata = ScrapeVec(urlvec)\n",
        "    jobdata[\"url\"] = urlvec\n",
        "    jobdata[\"date_added\"] = str(datetime.date.today())\n",
        "    jobdata.to_csv(\"ScrapedData.csv\",index=False)\n",
        "    CreateAppendDB(jobdata)\n",
        "    print(jobdata)\n",
        "\n",
        "if __name__ == '__main__':Main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFUMM37aA2Vf"
      },
      "source": [
        "# Querying the database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnrrcToKalv4"
      },
      "source": [
        "Sending an email with new jobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lc9OspiC6Vsz",
        "outputId": "18df3800-f7bd-4c39-d948-7f01a6a37f44"
      },
      "source": [
        "db=sqlite3.connect(\"MaltaJobs.db\")\r\n",
        "new_result = pd.read_sql(\"select * from Jobs where date_added ='{}'\".format(str(datetime.date.today())),db)\r\n",
        "new_result.to_csv(\"new_result.csv\",index=False)\r\n",
        "new_list = \"Kindly find new jobs below: \\n\"\r\n",
        "for i in range(0,len(new_result)):\r\n",
        "  string_new = new_result[\"title\"][i] + \" at \" +  new_result[\"company\"][i] + \" added on \" +  new_result[\"date_added\"][i] + \" with URL \" + new_result[\"url\"][i] + \"\\n\"\r\n",
        "  new_list += string_new\r\n",
        "new_list = new_list.replace(\"\\u2013\",\"\")\r\n",
        "print(new_list)\r\n",
        "\r\n",
        "import email, smtplib, ssl\r\n",
        "from email import encoders\r\n",
        "from email.mime.base import MIMEBase\r\n",
        "from email.mime.multipart import MIMEMultipart\r\n",
        "from email.mime.text import MIMEText\r\n",
        "\r\n",
        "email_list = [\"lukejohnsaid1989@gmail.com\"]\r\n",
        "\r\n",
        "for i in email_list:\r\n",
        "  subject = \"Automated: New jobs today on Careerjet\"\r\n",
        "  body = \"Good day! \\n Attached kindly find new job listings which have been added today from Careerjet. \"\r\n",
        "  sender_email = 'lukejohnsaid1989@gmail.com'\r\n",
        "  receiver_email = i\r\n",
        "  password = '*****'\r\n",
        "\r\n",
        "  # Create a multipart message and set headers\r\n",
        "  message = MIMEMultipart()\r\n",
        "  message[\"From\"] = sender_email\r\n",
        "  message[\"To\"] = receiver_email\r\n",
        "  message[\"Subject\"] = subject\r\n",
        "  message[\"Bcc\"] = receiver_email  # Recommended for mass emails\r\n",
        "\r\n",
        "  # Add body to email\r\n",
        "  message.attach(MIMEText(body, \"plain\"))\r\n",
        "\r\n",
        "  filename = \"new_result.csv\"  # In same directory as script\r\n",
        "\r\n",
        "  # Open PDF file in binary mode\r\n",
        "  with open(filename, \"rb\") as attachment:\r\n",
        "      # Add file as application/octet-stream\r\n",
        "      # Email client can usually download this automatically as attachment\r\n",
        "      part = MIMEBase(\"application\", \"octet-stream\")\r\n",
        "      part.set_payload(attachment.read())\r\n",
        "\r\n",
        "  # Encode file in ASCII characters to send by email    \r\n",
        "  encoders.encode_base64(part)\r\n",
        "\r\n",
        "  # Add header as key/value pair to attachment part\r\n",
        "  part.add_header(\r\n",
        "      \"Content-Disposition\",\r\n",
        "      f\"attachment; filename= {filename}\",\r\n",
        "  )\r\n",
        "\r\n",
        "  # Add attachment to message and convert message to string\r\n",
        "  message.attach(part)\r\n",
        "  text = message.as_string()\r\n",
        "\r\n",
        "  # Log in to server using secure context and send email\r\n",
        "  context = ssl.create_default_context()\r\n",
        "  with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\r\n",
        "      server.login(sender_email, password)\r\n",
        "      server.sendmail(sender_email, receiver_email, text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kindly find new jobs below: \n",
            "Internal Accountant at Quad Consultancy added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mt4c0fed48ac7459e35d5e72890161cbdc\n",
            "German speaking Night Shift only - Customer Support agent to world known client in Malta at Nordic Jobs Worldwide added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mtee075877a26e971035966184ea2a1fd4\n",
            "Backend Developer (PHP) at Videoslots added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mte8b944b2fd54fc33e3de56d94c158825\n",
            "Customer Service Agent (German speaking) at Videoslots added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mtcf7ab5f7888d55ea52a5b6b415ef6e99\n",
            "German-speaking Customer Support Agent at Aspire Global added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mt6838306067013bbb1f519b45478cede1\n",
            "Auditor at GRS Recruitment added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mt828bbe8f24a7a64eee67e33243d28b9f\n",
            "Quality Control  Laboratory Assistant at ASG Pharma added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mt80773db307171b65b2f4d76d257230c8\n",
            "Senior Sportsbook Affiliate Manager at The Stars Group added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mtf24207d26b6c11e3fe7ffd3999755bd5\n",
            "Hospitality Maintenance Worker and Deck Hand at MAYPOLE (VALLETTA) LIMITED added on 2020-12-10 with URL https://www.careerjet.com.mt/jobad/mt6a2ec7af24d278bb637de6e4f1f5187e\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}